# ðŸ“– Full Stack Practice of the Large Language Model Training @ RLChina 2024

A full stack practice to train a large language model.

This is technical material suitable for LLM training engineers and researchers interested in LLM. That is the content here contains pieces of completed scripts and `.ipynb`-format-files to enable you to quickly training and using LLM.

note: The list of topics will be improved over time, the first version is used for the courses in RLChina 2024, Guangzhou.

## [Data Curation](./data_curation/)

## [LLM Model Setup](./llm_model_setup/)

## [LLM_PreTraining](./llm_pretraining/)

## [LLM PostTraining](./llm_posttraining/)

## [LLM Deployment](./llm_deployment/)

## [Resources and References](./resource_and_references/)

## License

Unless specified otherwise the code in this repo is licensed under [Apache License, Version 2.0](https://www.apache.org/licenses/LICENSE-2.0).
